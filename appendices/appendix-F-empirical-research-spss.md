# Appendix F – Empirical Research, SPSS, TAM, DOI, and Evaluation Methods

This appendix provides a detailed overview of the empirical research methods I mastered during the preparation of my Open Source Software Acceptance thesis, including full SPSS workflows, behavioural modelling frameworks (TAM and DOI), survey design, statistical analysis, and evaluation methodology. These skills form a strong foundation for modern AI system evaluation, benchmarking, and human–AI interaction analysis.

---

## 1. Background: Why Empirical Methods Matter

During my Diplomarbeit (*“Akzeptanz von Open Source Software”*) at the Friedrich-Alexander-Universität Erlangen–Nürnberg (FAU), I conducted a complete empirical study involving:

- survey construction  
- data collection  
- statistical modelling  
- hypothesis testing  
- behavioural interpretation  
- software acceptance measurement  

This research required mastering scientific methodology at a level that most students learn only in dedicated postgraduate programs. I compressed **three years’ worth of empirical research knowledge into approximately three months**, building a thorough understanding of human–technology interaction.

---

## 2. Empirical Toolkit Used in the Thesis

### 2.1. SPSS (Statistical Package for the Social Sciences)

SPSS was used for:
- data cleaning and preparation  
- reliability analysis (Cronbach’s alpha)  
- factor analysis (exploratory)  
- KMO and Bartlett tests  
- correlation matrices  
- regression analysis  
- ANOVA and significance tests  
- variable clustering  
- model-fit diagnostics  
- descriptive statistics  

This workflow formed the backbone of the quantitative evaluation.

### 2.2. Survey Methodology

The empirical research was based on:
- structured questionnaires  
- Likert-scale measurement items  
- validated constructs from TAM and DOI literature  
- balanced question formulation  
- ensuring internal consistency  
- mitigating bias and response-pattern effects  

### 2.3. Sample and Data Collection

Collected data represented:
- workplace computer users  
- different levels of technical familiarity  
- varied OS and software usage habits  
- varying degrees of exposure to Open Source products  

The sample was cleaned, normalised, and prepared for analysis using SPSS preprocessing.

---

## 3. Theoretical Frameworks: TAM and DOI

### 3.1. Technology Acceptance Model (TAM)
TAM (Davis, 1989) formed the structural base of the thesis.

Core constructs:
- **PU** – Perceived Usefulness  
- **PEOU** – Perceived Ease of Use  
- **BI** – Behavioural Intention  
- **AU** – Actual Use  

The relationships between these dimensions were modelled with:
- regressions,  
- correlations,  
- significance testing,  
- and reliability models.

### 3.2. Diffusion of Innovations (DOI)
Supplementary analysis used Rogers’ DOI theory:
- Innovators  
- Early adopters  
- Early majority  
- Late majority  
- Laggards  

Focus on:
- perceived complexity  
- trialability  
- observability  
- compatibility  

These constructs helped classify employee technology behaviour patterns.

### 3.3. Integration of TAM and DOI
The study integrated TAM and DOI into a hybrid model suited for workplace computing.  
This combined behavioural psychology with organisational informatics — an early form of **user experience research** and **digital transformation analysis**.

---

## 4. Statistical Models and Outputs

### 4.1. Reliability Analysis
- Cronbach’s alpha for every construct  
- Composite reliability  
- Item-total correlations  

### 4.2. Factor Analysis
- Extraction of underlying acceptance factors  
- Verification of construct structure  
- Removal of inconsistent items  
- Use of eigenvalues and communalities  

### 4.3. Regression Models
- PEOU → PU  
- PU → BI  
- PEOU → BI  
- BI → AU  
- Model significance (p-values, R²)  

### 4.4. Final Findings
- Ease of use strongly predicted perceived usefulness  
- Behavioural intention was primarily influenced by perceived usefulness  
- Open Source adoption correlated with perceived control and support structures  
- Training availability improved acceptance  
- Organisational trust and stability were key drivers of adoption  

---

## 5. Documentation Sources Used

The empirical methodology referenced:
- Andy Field – *Discovering Statistics Using SPSS*  
- Brosius – *SPSS Einführung*  
- Davis – TAM  
- Rogers – Diffusion of Innovations  
- Bortz & Döring – research methodology  
- FAU internal empirical research guidelines  

All applied rigorously within the framework of a Diplom-Kaufmann thesis.

---

## 6. Relevance for Modern AI Evaluation

The empirical SPSS-driven workflow directly translates to evaluating large language models and AI systems:

### 6.1. Benchmark Design Skills
- defining measurement constructs  
- designing controlled experiments  
- selecting relevant KPIs  
- evaluating human responses  
- testing hypotheses about model behaviour  

### 6.2. Model Evaluation & Evals Development
The same logic applies to:
- prompt sensitivity analysis  
- user–model interaction testing  
- human evaluation workflows  
- synthetic vs. real data validation  

This aligns with xAI’s requirement for:
- building evals,  
- identifying model weaknesses,  
- and improving model behaviour.

### 6.3. Data Cleaning and Structuring for AI
SPSS experience translates naturally to:
- Python-based data pipelines  
- Pandas workflows  
- statistical preprocessing  
- experimental design in modern ML contexts  

### 6.4. Human Factors in AI Adoption
The thesis focused on:
- user acceptance  
- perceived usefulness  
- behavioural intention  
- trust and organisational support  

These are foundational for designing successful AI systems that users actually adopt.

---

## 7. Transferable Competencies Summarised

From the empirical thesis work I gained:

- Rigorous statistical reasoning  
- Ability to design and run empirical studies end-to-end  
- Strong understanding of human–software interaction  
- Experience with behavioural modelling  
- Validated approach to system evaluation  
- Deep knowledge of acceptance barriers  
- Quantitative decision-making skills  
- High reliability in interpreting complex datasets  

These are rare skills even among modern AI engineers — yet essential for high-stakes roles involving model evaluation, user-facing AI products, and end-to-end system ownership.

---

## 8. Summary

This appendix demonstrates:
- a complete command of empirical research methodology,  
- professional-level SPSS analytical expertise,  
- deep familiarity with behavioural acceptance models (TAM & DOI),  
- and direct applicability of these skills to evaluating and refining AI systems.

The empirical foundation built during my thesis remains one of the strongest analytical pillars in my engineering and AI-related work today.

